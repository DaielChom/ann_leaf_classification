{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    print (\"setting tensorflow version in colab\")\n",
    "    %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import lib as mlutils\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, concatenate, Input, Conv2D,Flatten\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from importlib import reload\n",
    "reload(lib)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/user/DeepLearning/projects/datasets/leaf_classification/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from the .csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intersection between train and test set is 0\n",
      "There are 99 classes for the classification task.\n"
     ]
    }
   ],
   "source": [
    "split=0.7\n",
    "X_train_f, _, X_train_ri, y_train, X_test_f, _, X_test_ri, y_test, species, num_classes, _, _ = lib.get_splitted_data(data_dir=data_dir, check_id_sets=True, verbose=1, use_resize_images=True, split=split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traget onehot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = np.eye(99)[y_train]#num_classes\n",
    "y_test_oh  = np.eye(num_classes)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ri = X_train_ri.reshape((X_train_ri.shape[0], X_train_ri.shape[1], X_train_ri.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ri = X_test_ri.reshape((X_test_ri.shape[0], X_test_ri.shape[1], X_test_ri.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((693, 194), (693, 128, 128, 1), (693, 99))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_f.shape, X_train_ri.shape, y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((297, 194), (297, 128, 128, 1), (297, 99))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_f.shape, X_test_ri.shape, y_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainif = np.r_[[i.flatten() for i in X_train_ri]]\n",
    "x_testif  = np.r_[[i.flatten() for i in X_test_ri]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(num_classes, img_size=32, compile=True):\n",
    "    print(\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    layers = tf.keras.layers.Conv2D(2,(3,3), activation=\"relu\")(inputs) \n",
    "    layers = tf.keras.layers.BatchNormalization()(layers)\n",
    "    layers = tf.keras.layers.Flatten()(layers)\n",
    "    layers = tf.keras.layers.Dense(100, activation=tf.nn.relu)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization()(layers)\n",
    "    layers = tf.keras.layers.Dense(100, activation=tf.nn.relu)(layers)\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax, name=\"output_1\")(layers)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    if compile:\n",
    "        model.compile(optimizer='RMSprop',loss='categorical_crossentropy' ,metrics=['accuracy'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 99 classes\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 126, 126, 2)       20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 126, 126, 2)       8         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 31752)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               3175300   \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output_1 (Dense)             (None, 99)                9999      \n",
      "=================================================================\n",
      "Total params: 3,195,827\n",
      "Trainable params: 3,195,623\n",
      "Non-trainable params: 204\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#instantiate the model\n",
    "num_classes = len( y_test_oh[1])\n",
    "model = get_conv_model(num_classes,img_size=128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batch_size, epochs, model_name=\"\"):\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\"+model_name+\"_\"+\"{}\".format(time()))\n",
    "    model.reset_states()\n",
    "    model.fit(X_train_ri.astype(np.float32), y_train_oh.astype(int), epochs=epochs, callbacks=[tensorboard], batch_size=batch_size, validation_data=( X_test_ri, y_test_oh))\n",
    "    metrics = model.evaluate( X_test_ri.astype(np.float32), y_test_oh.astype(int))\n",
    "    return {k:v for k,v in zip (model.metrics_names, metrics)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 693 samples, validate on 297 samples\n",
      "Epoch 1/10\n",
      "693/693 [==============================] - 5s 8ms/sample - loss: 4.3339 - accuracy: 0.0577 - val_loss: 4.5877 - val_accuracy: 0.0505\n",
      "Epoch 2/10\n",
      "693/693 [==============================] - 4s 6ms/sample - loss: 3.3432 - accuracy: 0.2266 - val_loss: 7.7295 - val_accuracy: 0.0303\n",
      "Epoch 3/10\n",
      "693/693 [==============================] - 4s 6ms/sample - loss: 2.1918 - accuracy: 0.5339 - val_loss: 8.9575 - val_accuracy: 0.0337\n",
      "Epoch 4/10\n",
      "693/693 [==============================] - 5s 8ms/sample - loss: 1.3784 - accuracy: 0.7460 - val_loss: 10.5386 - val_accuracy: 0.0404\n",
      "Epoch 5/10\n",
      "693/693 [==============================] - 5s 8ms/sample - loss: 0.7475 - accuracy: 0.8903 - val_loss: 7.5199 - val_accuracy: 0.0572\n",
      "Epoch 6/10\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.4565 - accuracy: 0.9307 - val_loss: 5.1121 - val_accuracy: 0.1414\n",
      "Epoch 7/10\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.2489 - accuracy: 0.9668 - val_loss: 12.6509 - val_accuracy: 0.0269\n",
      "Epoch 8/10\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.2485 - accuracy: 0.9452 - val_loss: 3.4690 - val_accuracy: 0.2795\n",
      "Epoch 9/10\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.1651 - accuracy: 0.9654 - val_loss: 3.5059 - val_accuracy: 0.2929\n",
      "Epoch 10/10\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.1278 - accuracy: 0.9784 - val_loss: 2.7984 - val_accuracy: 0.4108\n",
      "297/297 [==============================] - 1s 2ms/sample - loss: 2.7984 - accuracy: 0.4108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 2.7983851264221498, 'accuracy': 0.4107744}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, batch_size=8, epochs=10, model_name=\"model_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lib' has no attribute 'plot_confusion_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-13fab21863bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_ri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lib' has no attribute 'plot_confusion_matrix'"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(X_train_ri).argmax(axis=1)\n",
    "mlutils.plot_confusion_matrix(y_train_oh, test_preds, classes=np.r_([i for i in range(99)]), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second model with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(num_classes, img_size=32, compile=True):\n",
    "    print(\"using\",num_classes,\"classes\")\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    layers = tf.keras.layers.Conv2D(2,(3,3), activation=\"relu\")(inputs) \n",
    "    layers = tf.keras.layers.BatchNormalization()(layers)\n",
    "    layers = tf.keras.layers.Flatten()(layers)\n",
    "    layers = tf.keras.layers.Dense(200, activation=tf.nn.relu)(layers)#change number of neurons of dense layer\n",
    "    layers = tf.keras.layers.BatchNormalization()(layers)\n",
    "    layers = tf.keras.layers.Dense(100, activation=tf.nn.relu)(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax, name=\"output_1\")(layers)\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    if compile:\n",
    "        model.compile(optimizer='RMSprop',loss='categorical_crossentropy' ,metrics=['accuracy'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 99 classes\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 126, 126, 2)       20        \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 31752)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 200)               6350600   \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output_1 (Dense)             (None, 99)                9999      \n",
      "=================================================================\n",
      "Total params: 6,380,719\n",
      "Trainable params: 6,380,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#instantiate the model\n",
    "num_classes = len( y_test_oh[1])\n",
    "model1 = get_conv_model(num_classes,img_size=128)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model1, batch_size, epochs, model_name=\"\"):\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\"+model_name+\"_\"+\"{}\".format(time()))\n",
    "    model.reset_states()\n",
    "    model.fit(X_train_ri.astype(np.float32), y_train_oh.astype(int), epochs=epochs, callbacks=[tensorboard], batch_size=batch_size, validation_data=( X_test_ri, y_test_oh))\n",
    "    metrics = model.evaluate( X_test_ri.astype(np.float32), y_test_oh.astype(int))\n",
    "    return {k:v for k,v in zip (model.metrics_names, metrics)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 693 samples, validate on 297 samples\n",
      "Epoch 1/20\n",
      "693/693 [==============================] - 5s 7ms/sample - loss: 0.0036 - accuracy: 0.9986 - val_loss: 4.9929 - val_accuracy: 0.4209\n",
      "Epoch 2/20\n",
      "693/693 [==============================] - 4s 6ms/sample - loss: 0.0066 - accuracy: 0.9986 - val_loss: 11.8920 - val_accuracy: 0.1448\n",
      "Epoch 3/20\n",
      "693/693 [==============================] - 4s 6ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.4273 - val_accuracy: 0.4613\n",
      "Epoch 4/20\n",
      "693/693 [==============================] - 5s 8ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 16.0824 - val_accuracy: 0.0842\n",
      "Epoch 5/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0038 - accuracy: 0.9971 - val_loss: 6.0636 - val_accuracy: 0.3603\n",
      "Epoch 6/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.0114 - val_accuracy: 0.4512\n",
      "Epoch 7/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0152 - accuracy: 0.9957 - val_loss: 4.9202 - val_accuracy: 0.4209\n",
      "Epoch 8/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0046 - accuracy: 0.9971 - val_loss: 5.4179 - val_accuracy: 0.3939\n",
      "Epoch 9/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0066 - accuracy: 0.9971 - val_loss: 5.9855 - val_accuracy: 0.3704\n",
      "Epoch 10/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0018 - accuracy: 0.9986 - val_loss: 25.7677 - val_accuracy: 0.0337\n",
      "Epoch 11/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 13.0295 - val_accuracy: 0.0976\n",
      "Epoch 12/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.2088 - val_accuracy: 0.4007\n",
      "Epoch 13/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0271 - accuracy: 0.9942 - val_loss: 7.8556 - val_accuracy: 0.3165\n",
      "Epoch 14/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0132 - accuracy: 0.9957 - val_loss: 10.9016 - val_accuracy: 0.1785\n",
      "Epoch 15/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0051 - accuracy: 0.9986 - val_loss: 4.5113 - val_accuracy: 0.4613\n",
      "Epoch 16/20\n",
      "693/693 [==============================] - 6s 9ms/sample - loss: 0.0032 - accuracy: 0.9986 - val_loss: 5.3952 - val_accuracy: 0.4276\n",
      "Epoch 17/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.1047 - val_accuracy: 0.4242\n",
      "Epoch 18/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.0375 - val_accuracy: 0.4276\n",
      "Epoch 19/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0064 - accuracy: 0.9986 - val_loss: 5.5021 - val_accuracy: 0.3704\n",
      "Epoch 20/20\n",
      "693/693 [==============================] - 6s 8ms/sample - loss: 0.0147 - accuracy: 0.9942 - val_loss: 10.2532 - val_accuracy: 0.2054\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 10.2532 - accuracy: 0.2054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 10.25324668306293, 'accuracy': 0.2053872}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model1, batch_size=8, epochs=20, model_name=\"model_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
